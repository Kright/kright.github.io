<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Как можно взять tensorflow и смешать две картинки в одну | kright.github.io</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Как можно взять tensorflow и смешать две картинки в одну" />
<meta name="author" content="kright" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Как можно взять tensorflow и смешать две картинки в одну" />
<meta property="og:description" content="Как можно взять tensorflow и смешать две картинки в одну" />
<link rel="canonical" href="http://localhost:4000/2021/11/25/%D0%9A%D0%B0%D0%BA-%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE-%D0%B2%D0%B7%D1%8F%D1%82%D1%8C-tensorflow-%D0%B8-%D1%81%D0%BC%D0%B5%D1%88%D0%B0%D1%82%D1%8C-%D0%B4%D0%B2%D0%B5-%D0%BA%D0%B0%D1%80%D1%82%D0%B8%D0%BD%D0%BA%D0%B8-%D0%B2-%D0%BE%D0%B4%D0%BD%D1%83.html" />
<meta property="og:url" content="http://localhost:4000/2021/11/25/%D0%9A%D0%B0%D0%BA-%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE-%D0%B2%D0%B7%D1%8F%D1%82%D1%8C-tensorflow-%D0%B8-%D1%81%D0%BC%D0%B5%D1%88%D0%B0%D1%82%D1%8C-%D0%B4%D0%B2%D0%B5-%D0%BA%D0%B0%D1%80%D1%82%D0%B8%D0%BD%D0%BA%D0%B8-%D0%B2-%D0%BE%D0%B4%D0%BD%D1%83.html" />
<meta property="og:site_name" content="kright.github.io" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-25T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Как можно взять tensorflow и смешать две картинки в одну" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"kright"},"dateModified":"2021-11-25T00:00:00+01:00","datePublished":"2021-11-25T00:00:00+01:00","description":"Как можно взять tensorflow и смешать две картинки в одну","headline":"Как можно взять tensorflow и смешать две картинки в одну","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2021/11/25/%D0%9A%D0%B0%D0%BA-%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE-%D0%B2%D0%B7%D1%8F%D1%82%D1%8C-tensorflow-%D0%B8-%D1%81%D0%BC%D0%B5%D1%88%D0%B0%D1%82%D1%8C-%D0%B4%D0%B2%D0%B5-%D0%BA%D0%B0%D1%80%D1%82%D0%B8%D0%BD%D0%BA%D0%B8-%D0%B2-%D0%BE%D0%B4%D0%BD%D1%83.html"},"url":"http://localhost:4000/2021/11/25/%D0%9A%D0%B0%D0%BA-%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE-%D0%B2%D0%B7%D1%8F%D1%82%D1%8C-tensorflow-%D0%B8-%D1%81%D0%BC%D0%B5%D1%88%D0%B0%D1%82%D1%8C-%D0%B4%D0%B2%D0%B5-%D0%BA%D0%B0%D1%80%D1%82%D0%B8%D0%BD%D0%BA%D0%B8-%D0%B2-%D0%BE%D0%B4%D0%BD%D1%83.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=04936c4141575b8269035838047e98a4dd849258">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Как можно взять  tensorflow и смешать две картинки в одну</h1>
      <h2 class="project-tagline"></h2>
      
        <a href="https://github.com/Kright/kright.github.io" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<nav>
  <a href="/">Home</a>
  <a href="/about.html">About</a>
</nav>


<p>25 Nov 2021</p>

<h1 id="как-можно-взять--tensorflow-и-смешать-две-картинки-в-одну">Как можно взять  tensorflow и смешать две картинки в одну</h1>

<p>Возможно, вы встречали изображения, в которых смешаны два образа. Вблизи виден один, а издалека - другой. Например, Эйнштейн и Мадонна.</p>

<p>Не знаю, как делались оригинальные, но я попробовал сделать нечто похожее с помощью tensorflow.</p>

<p><img src="/assets/images/2021/tensorflow/kpdv.png" alt="" /></p>

<p>Общая идея: взять машинное обучение и с его помощью подогнать изображение. Обратите внимание: я не учу модель, которая будет из двух картинок делать одну. Модель - это просто массив цветов пикселей, и больше ничего. В процессе “обучения” возьмём две картинки-образца и будет улучшать “похожесть” на них.
Для первого образца функцией ошибки будет попиксельная разница цветов с обучаемой картинкой. Для второго - отличие между размытым образцом и размытой картинкой.</p>

<p>Преобразование Фурье - прошлый век, новые проблемы требуют инновационных решений.</p>

<p>Код и исходные картинки <a href="https://github.com/Kright/mix-two-images-in-one/blob/master/twoImages.ipynb">лежат на гитхабе</a>.</p>

<p>Для запуска понадобитя tensorflow, numpy и Pillow. Для последней версии tensorflow понадобится python 3.7 или новее.</p>

<p>Чтобы результат получался за пару минут при вычислении на процессоре, я уменьшил картинки до размера 512х512 пикселей. Взял их из википедии: шахматы и девушка Лена.</p>

<p><img src="/assets/images/2021/tensorflow/chess.png" alt="" /></p>

<p><img src="/assets/images/2021/tensorflow/lena.png" alt="" /></p>

<p>Загрузим их и переведём во float в интервале от 0 до 1:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lena</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="s">"imgs/Lenna512.png"</span><span class="p">)</span>
<span class="n">chess</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="s">"imgs/ChessSet512.png"</span><span class="p">)</span>
<span class="n">imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">lena</span><span class="p">,</span> <span class="n">chess</span><span class="p">]]</span>
</code></pre></div></div>

<h3 id="гамма-коррекция">Гамма-коррекция</h3>

<p>Воспринимаемая глазом яркость света может отличаться на много-много порядков. В изображениях с одним байтом яркости на канал есть 256 значений яркости и в физическое количество фотонов они отображаются нелинейно. Например, от двух пикселей с яркостью 127 света будет меньше, чем от одного с яркостью 254.</p>

<p>Для перевода в физическое значение яркости существует гамма-коррекция: возведение яркости в степень 2.2. Получится величина, пропорциональная количеству фотонов с экрана. Обратное преобразование тоже делается просто - возведением в степень 1/2.2.</p>

<p>Зачем всё это нужно? Если я хочу узнать видимую разницу цветов, можно просто взять разницу значений в обычном RGB пространстве.</p>

<p>При рассчёте того, как будет выглядеть изображение издалека (размытое), будет необходимо перевести значения яркости в линейное пространство (пропорциональное количеству фотонов) и уже в нём сделать размытие по Гауссу.</p>

<h3 id="размытие-по-гауссу">Размытие по Гауссу</h3>

<p>При размытии картинки каждый пиксель превращается в пятнышко. На математическом языке пятнышко называется ядром, а сам процесс - свёрткой.
Ядро выглядит как-то так \(Ce^{- \frac{dx^2+dy^2}{2 \sigma^2}} = C e^{-\frac{dx^2}{2 \sigma^2}} e^{-\frac{dy^2}{2 \sigma^2}}\)
C - некая константа, чтобы сумма всех элементов (или интеграл по площади) равнялась единице и яркость изображения не изменялась. По этой же причине надо сделать гамма-коррекцию, чтобы работать с физическим количеством света.</p>

<p>Особенностью свёртки с этим ядром является то, что его её можно сделать сначала по одной оси, а затем по другой, так что достаточно посчитать ядро для одномерного случая:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_gauss_blur_kernel</span><span class="p">(</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>  
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>  
    <span class="n">center</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>  
    <span class="n">div</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>  
        <span class="n">x2</span> <span class="o">=</span> <span class="p">(</span><span class="n">center</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> 
		<span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span><span class="n">x2</span> <span class="o">/</span> <span class="n">div</span><span class="p">)</span>  
    <span class="k">return</span> <span class="n">result</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  
  
<span class="n">make_gauss_blur_kernel</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<p>Математически ядро бесконечное, но мы ограничим его размеры. Например, для sigma =2 и размера ядра в 11 получится так:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">array</span><span class="p">([</span><span class="mf">0.00881223</span><span class="p">,</span> <span class="mf">0.02714358</span><span class="p">,</span> <span class="mf">0.06511406</span><span class="p">,</span> <span class="mf">0.12164907</span><span class="p">,</span> <span class="mf">0.17699836</span><span class="p">,</span> <span class="mf">0.20056541</span><span class="p">,</span> <span class="mf">0.17699836</span><span class="p">,</span> <span class="mf">0.12164907</span><span class="p">,</span> <span class="mf">0.06511406</span><span class="p">,</span> <span class="mf">0.02714358</span><span class="p">,</span> <span class="mf">0.00881223</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="tensorflow-20">tensorflow 2.0</h3>

<p>В старой tensorflow граф модели был неизменяемым, и это накладывало ограничения. В версии 2.0 утащили фишку из питона - граф модели строится динамически прямо в процессе вычисления ошибки, а потом можно взять и вычислить градиенты.</p>

<p><img src="/assets/images/2021/tensorflow/cat.png" alt="" /></p>

<p>Магия выглядит вот так:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
	<span class="c1"># computations
</span>	<span class="n">loss</span> <span class="o">=</span> <span class="p">...</span>
	
<span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">trainable_variables</span><span class="p">)</span>	
</code></pre></div></div>

<p>Это как раз то, что нам нужно.</p>

<h3 id="создаём-модель">создаём модель</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_h</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">img_w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">gauss_kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">gauss_sigma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">image_source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">image_source</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">image_source</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">img_h</span><span class="p">,</span> <span class="n">img_w</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">trainable_image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="n">image_source</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">gauss_blur_kernel</span> <span class="o">=</span> <span class="n">make_gauss_blur_kernel</span><span class="p">(</span><span class="n">gauss_kernel_size</span><span class="p">,</span> <span class="n">gauss_sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gauss_kernel_x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">gauss_blur_kernel</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gauss_kernel_y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">gauss_blur_kernel</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
		
	<span class="p">...</span>
</code></pre></div></div>

<p>trainable_image - переменные. Из них состоит наша “обучаемая” картинка. Их мы будем подгонять, чтобы было похоже на нужные две картинки.
Так же сделаем константы для ядер свёрток по осям х и у. Их учить не будем, они и так получены умным путём.</p>

<p>Для свёрток используется аж четырёхмерное ядро:</p>
<ol>
  <li>ось У изображения</li>
  <li>ось Х изображения</li>
  <li>количество входных каналов (3)</li>
  <li>количество выходных каналов на каждый входной канал (1, каждый цвет переходит сам в себя)</li>
</ol>

<p>Кроме того, и в numpy и в tensorflow есть идея броадкастинга. Например, массив с размерностями (1, 256, 512, 1) можно интерпретировать как (N, 256, 512, C) - как будто по первой и последней оси размер произвольный, а числа одни и те же. Броадкастинг в этих библиотеках иногда работает по-разному, функция свёртки хочет увидеть ядро размероностью именно (size_x, size_y, 3, 1) и почему-то недовольно массивом (size_x, size_y, 1, 1), так что пришлось в numpy умножить на массив единичек размерностью (1, 1, 3, 1). Если бы мы сделали разные ядра свёрток для разных цветов, то нам бы пригодилась эта размерность, но у нас всё одинаково.</p>

<p>Я использую поканальные свёртки (чтобы канал R при размытии влиял только на себя и превращался в новый канал R). Они считаются быстрее обычных. А ещё внутри нет никакого преобразования Фурье, и сложность вычисления свёртки зависит линейно от размера ядра. По этой же причине свёртка с квадратным ядром размера 15x15 будет считаться в несколько раз дольше, чем две свёртки с ядрами 1х15 и 15х1.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">:</span>
	<span class="p">...</span>


    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_precise</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">img_blurred</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">m_precise</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m_blurred</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Report</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
			<span class="c1"># next code will be here
</span>
</code></pre></div></div>

<p>Для шага обучения возьмём две картинки и коэффициенты для важности ошибок у каждой.</p>

<p>Обучаемые переменные могут быть любыми, хоть -1, хоть 9000. Но в качестве цветов картинки хочется получить значения в интвервале от 0 до 1. Для этого применим <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%B3%D0%BC%D0%BE%D0%B8%D0%B4%D0%B0">сигмоиду</a>.: около нуля она более-менее линейно растёт, но на больших входных значениях рост замедляется и результат никогда не превысит единицу.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainable_image01</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">trainable_image</span><span class="p">)</span>
</code></pre></div></div>

<p>Для первой картинки (которая должна быть резкой) разница - просто сумма квадратов разностей яркости для каждого канала каждого пикселя. По-идее, каждый пиксель учится независимо, и шаг обучения в 0.1 будет вполне нормальным.</p>

<p>Вместо суммы можно было бы использовать reduce_mean(), но тогда градиенты были бы меньше на площадь картинки (512x512) и пришлось бы градиенты умножать на что-то типа 10^5.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_precise</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">trainable_image01</span> <span class="o">-</span> <span class="n">img_precise</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]))</span>
</code></pre></div></div>

<p>Для второй картинки сделаем размытие (свёртку), а потом точно так же попиксельно сравним. И не забудем про гамма-коррекцию до свёртки и обратную после:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">blurred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">gauss_blur</span><span class="p">(</span><span class="n">trainable_image01</span> <span class="o">**</span> <span class="mf">2.2</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">2.2</span><span class="p">)</span>
<span class="n">blurred_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">gauss_blur</span><span class="p">(</span><span class="n">img_blurred</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">**</span> <span class="mf">2.2</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">2.2</span><span class="p">)</span>
<span class="n">loss_gauss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">blurred</span> <span class="o">-</span> <span class="n">blurred_label</span><span class="p">))</span>
</code></pre></div></div>

<p>Домножим ошибки на коэффициенты и сложим. В зависимости от соотношения коэффициентов результат будет больше стремиться к одной картинке или другой.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_precise</span> <span class="o">*</span> <span class="n">m_precise</span> <span class="o">+</span> <span class="n">loss_gauss</span> <span class="o">*</span> <span class="n">m_blurred</span>
</code></pre></div></div>

<p>Вжух и получим градиенты:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">trainable_image</span><span class="p">)</span>
</code></pre></div></div>

<p>Для обучения есть разные оптимизаторы, но я прямо руками сделал простой градиентный спуск:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">apply_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">trainable_image</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">trainable_image</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span><span class="p">)</span>
</code></pre></div></div>

<p>Вызовем функцию много-много раз. Код в статье для иллюстрации, запускабельный вариант можно найти на гитхабе.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">:</span>
	<span class="p">...</span>
	<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">print_loss_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">**</span><span class="n">run_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Report</span><span class="p">:</span>
		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps_count</span><span class="p">):</span>
			<span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="o">**</span><span class="n">run_kwargs</span><span class="p">)</span>
			<span class="n">model</span><span class="p">.</span><span class="n">apply_gradient</span><span class="p">(</span><span class="n">r</span><span class="p">.</span><span class="n">gradient</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
			<span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">print_loss_steps</span> <span class="o">==</span> <span class="n">print_loss_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
				<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: loss = </span><span class="si">{</span><span class="n">r</span><span class="p">.</span><span class="n">loss</span><span class="si">}</span><span class="s">, precise = </span><span class="si">{</span><span class="n">r</span><span class="p">.</span><span class="n">loss_precise</span><span class="si">}</span><span class="s">, gauss = </span><span class="si">{</span><span class="n">r</span><span class="p">.</span><span class="n">loss_gauss</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
		<span class="k">return</span> <span class="n">r</span>
</code></pre></div></div>

<p>Теперь всё готово для обучения модели:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">gauss_kernel_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">gauss_sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">steps_count</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">print_loss_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">img_precise</span><span class="o">=</span><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">img_blurred</span><span class="o">=</span><span class="n">imgs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">m_precise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">m_blurred</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>  
<span class="n">Image</span><span class="p">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">r</span><span class="p">.</span><span class="n">image</span> <span class="o">*</span> <span class="mf">255.0</span><span class="p">))</span>
</code></pre></div></div>

<p>Я попробовал разные коэффициенты (0.1, 0.3, 1.0), ниже можно посмотреть картинки.</p>

<p><img src="/assets/images/2021/tensorflow/output3.png" alt="" />
<img src="/assets/images/2021/tensorflow/output4.png" alt="" />
<img src="/assets/images/2021/tensorflow/output5.png" alt="" /></p>

<h3 id="а-зачем-всё-это">А зачем всё это?</h3>

<p>Просто потому что могу. Мне нравится возможность задать произвольную функцию ошибки и обучить модель, не задумываясь над тем, как получить результат аналитически. Эксперименты с картинками делают происходящее очевидным.</p>

<p>Если Вам кажется, что я забиваю гвозди микроскопом и tensorflow совсем не для этого, то это не так. Библиотека даёт возможность легко считать градиенты, я этим пользуюсь как хочу. Машинное обучение не обязано происходить на кластерах с топовыми GPU и датасетами размером в терабайты.</p>

<p>При помощи преобразования Фурье и вырезания высоких частот с одной картинки и низких с другой можно получить похожий эффект. Но с некоторым оговорками: тоже могут получаться значения яркости меньше 0 и больше 1. И я не знаю, как сочетать логарифмическое восприятие яркости человеческим глазом и необходимость делать размытие по Гауссу в линейном цветовом пространстве. Я попробовал, результат мне не понравился. Пруфов не будет.</p>

<p>Вариант с обучением на порядки медленнее Фурье и на моём ноутбуке занимает несколько минут. На мой взгляд это не страшно, так как намного больше времени я потратил на написание кода. У меня нет задачи генерировать тысячи картинок, одной вполне достаточно для понимания процесса.</p>

<p>Изначальное состояние обучаемой модели - серая картинка. Если важна производительность, можно в качестве первого приближения взять одну из картинок или даже результаты экспериментов с Фурье. Но в случае с одной картинкой написание и отладка этого кода займёт больше времени, чем обучение с нуля, а результат будет примерно тот же.</p>

<p><a href="https://habr.com/ru/post/591409/">Пост на хабре</a></p>




      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/Kright/kright.github.io">kright.github.io</a> is maintained by <a href="https://github.com/Kright">Kright</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
